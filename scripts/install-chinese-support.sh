#!/bin/bash
set -e

echo "ğŸ‡¨ğŸ‡³ Installing Chinese tokenizer support..."

# Create extensions directory
mkdir -p extensions

# Detect platform
if [[ "$OSTYPE" == "darwin"* ]]; then
    PLATFORM="darwin"
    EXT_FILE="libsimple.dylib"
elif [[ "$OSTYPE" == "linux-gnu"* ]]; then
    PLATFORM="linux" 
    EXT_FILE="libsimple.so"
else
    echo "âŒ Unsupported platform: $OSTYPE"
    echo "   Supported platforms: macOS (darwin), Linux (linux-gnu)"
    exit 1
fi

echo "ğŸ“¦ Downloading extension for $PLATFORM..."

# Download extension file
curl -L "https://github.com/wangfenjin/simple/releases/download/v0.5.2/$EXT_FILE" \
     -o "extensions/$EXT_FILE"

if [[ ! -f "extensions/$EXT_FILE" ]]; then
    echo "âŒ Failed to download extension file"
    exit 1
fi

# Download dictionary files
echo "ğŸ“š Downloading dictionary files..."
curl -L "https://github.com/wangfenjin/simple/releases/download/v0.5.2/dict.tar.gz" \
     | tar -xz -C extensions/

if [[ ! -d "extensions/dict" ]]; then
    echo "âŒ Failed to download dictionary files"
    exit 1
fi

echo "âœ… Chinese tokenizer support installed successfully!"
echo ""
echo "ğŸ“ Installed files:"
echo "   - extensions/$EXT_FILE"
echo "   - extensions/dict/ (Chinese dictionaries)"
echo ""
echo "ğŸ” You can now search Chinese text with improved word segmentation and Pinyin support."
echo "ğŸ“– Example searches:"
echo "   - Chinese: 'å‘¨æ°å€«' or 'è‡ªç„¶èªè¨€è™•ç†'"
echo "   - Pinyin: 'zhoujielun' or 'ziranyuyanchuli'"
echo ""
echo "ğŸš€ Start the MCP server with: npm run dev"